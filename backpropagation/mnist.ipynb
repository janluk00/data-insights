{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%pip install tensorflow\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Network:\n",
    "    def __init__(self, sizes: list, learning_rate) -> None:\n",
    "        self.num_layers = len(sizes)\n",
    "        self.sizes = sizes\n",
    "        self.learning_rate = learning_rate\n",
    "        self.biases = [np.random.randn(x, 1) for x in sizes[1:]]\n",
    "        self.weights = [np.random.randn(x, y) / np.sqrt(x)  for x, y in zip(sizes[1:], sizes[:-1])]\n",
    "\n",
    "    def feed_forward(self, activations):\n",
    "        for x, y in zip(self.biases, self.weights):\n",
    "            activations = self.sigmoid(np.dot(y, activations) + x)\n",
    "        \n",
    "        return activations.reshape(-1)\n",
    "\n",
    "    @staticmethod\n",
    "    def sigmoid(x):\n",
    "        return 1.0 / (1.0 + np.exp(-x))\n",
    "\n",
    "    @staticmethod\n",
    "    def cost(activations_out, y_vector):\n",
    "        y = y_vector.reshape(-1, 1)\n",
    "        return activations_out - y\n",
    "\n",
    "    def sigmoid_derivate(self, z):\n",
    "        return self.sigmoid(z) * (1.0 - self.sigmoid(z))\n",
    "    \n",
    "    def mini_batches(self, batch_size, shuffled_training_data):\n",
    "        return [shuffled_training_data[k:k+batch_size] for k in range(0, len(shuffled_training_data), batch_size)]\n",
    "    \n",
    "    def backpropagation(self, x, y):\n",
    "        # activations[-1] - output layer\n",
    "\n",
    "        biases = [np.zeros(b.shape) for b in self.biases]\n",
    "        weights = [np.zeros(w.shape) for w in self.weights]\n",
    "\n",
    "        activation = x # input layer\n",
    "        activations = [x]\n",
    "        out_vector = []\n",
    "      \n",
    "        for b, w in zip(self.biases, self.weights):\n",
    "            activation = activation.reshape(-1, 1)\n",
    "            a = np.dot(w, activation) + b\n",
    "            out_vector.append(a)\n",
    "            activation = self.sigmoid(a)\n",
    "            activations.append(activation.reshape(-1, 1))\n",
    "\n",
    "        delta = self.cost(activations[-1], y) * self.sigmoid_derivate(out_vector[-1]) \n",
    "         \n",
    "        biases[-1] = delta\n",
    "        weights[-1] = np.dot(delta, activations[-2].transpose())\n",
    "\n",
    "        for layer in range(2, self.num_layers): \n",
    "            delta = np.dot(self.weights[-layer + 1].transpose(), delta) * self.sigmoid_derivate(out_vector[-layer]) \n",
    "            biases[-layer] = delta\n",
    "            weights[-layer] = np.dot(delta, activations[-layer - 1].transpose()) \n",
    "\n",
    "        return (biases, weights)\n",
    "    \n",
    "    def update_batch(self, mini_batch):\n",
    "        new_weights = [np.zeros(w.shape) for w in self.weights]\n",
    "        new_biases = [np.zeros(b.shape) for b in self.biases]\n",
    "\n",
    "\n",
    "        for x, y in mini_batch:\n",
    "            biases, weights = self.backpropagation(x, y)\n",
    "\n",
    "            new_weights = [nw + w for nw, w in zip(new_weights, weights)]\n",
    "            new_biases = [nb + b for nb, b in zip(new_biases, biases)]\n",
    "\n",
    "            self.weights = [w - (self.learning_rate / len(mini_batch)) * nw for w, nw in zip(self.weights, new_weights)]\n",
    "            self.biases = [b - (self.learning_rate / len(mini_batch)) * nb for b, nb in zip(self.biases, new_biases)]\n",
    "\n",
    "\n",
    "    def train(self, data, epochs, batch_size=10, test_data=None):\n",
    "        n = len(data)\n",
    "        test_data_len = len(test_data) if test_data else None\n",
    "\n",
    "        for e in range(epochs):\n",
    "            shuffled_data = random.sample(data, k=n)\n",
    "            mini_batches = self.mini_batches(batch_size, shuffled_data)\n",
    "            for batch in mini_batches:\n",
    "                self.update_batch(batch)\n",
    "\n",
    "            if test_data:\n",
    "                print(f\"Epoch {e}: {self.evaluate(test_data)} / {test_data_len}\")\n",
    "            else:\n",
    "                print(f\"Epoch {e} complete!\")\n",
    "\n",
    "    def evaluate(self, data):\n",
    "        results = [(np.argmax(self.feed_forward(x)), y) for (x, y) in data]\n",
    "        \n",
    "        return sum(int(x == np.argmax(y)) for (x, y) in results)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vectorized_result(digit):\n",
    "    e = np.zeros((10, 1))\n",
    "    e[digit] = 1.0\n",
    "    return e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "(X_train, y_train), (X_test, y_test) = tf.keras.datasets.mnist.load_data()\n",
    "\n",
    "X_train_flat = [np.reshape(x, (784, 1)) for x in X_train]\n",
    "X_test_flat = [np.reshape(x, (784, 1)) for x in X_test]\n",
    "\n",
    "X_train_normalized = [x / 255.0 for x in X_train_flat]\n",
    "X_test_normalized = [x / 255.0 for x in X_test_flat]\n",
    "\n",
    "y_train_vector = [vectorized_result(x) for x in y_train]\n",
    "y_test_vector = [vectorized_result(x) for x in y_test]\n",
    "\n",
    "train_data = list(zip(X_train_normalized, y_train_vector))\n",
    "test_data = list(zip(X_test_normalized, y_test_vector))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = Network([784, 100, 50, 10], 0.5)\n",
    "n.train(data=train_data, epochs=10, batch_size=10, test_data=test_data)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
